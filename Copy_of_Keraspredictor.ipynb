{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Keraspredictor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmmCw8XhuhZDqz7/MqZRbQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunado/Coursera-Capstone/blob/master/Copy_of_Keraspredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NYF2q_iNFZsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aruna Dorai 13 March 2022\n"
      ],
      "metadata": {
        "id": "e5_AfLrYcAd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras Deep Learning Framework -"
      ],
      "metadata": {
        "id": "Qh7xDhdzcy_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "One hot encoding is a process of converting categorical data variables so they can be provided to machine learning algorithms to improve predictions. One hot encoding is a crucial part of feature engineering for machine learning."
      ],
      "metadata": {
        "id": "_e2KVMQddG3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding  "
      ],
      "metadata": {
        "id": "ByX1ebM9dIXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define your docuemnts"
      ],
      "metadata": {
        "id": "feQ2kSMlfKE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mysent = ['How are you', 'How is the weather', 'how is your pet', 'i am fine', 'i live in toronto', 'i have no pets']"
      ],
      "metadata": {
        "id": "phVQmR5pelq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "categorize and dfine class labels\n"
      ],
      "metadata": {
        "id": "vc0P2XzefUDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mysentlabels = array([1,1,1,0,0,0])"
      ],
      "metadata": {
        "id": "R1tZw5j6c4mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding of documents\n"
      ],
      "metadata": {
        "id": "7WC2emHggByX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myvocabsiz = 30\n",
        "encodsent = [one_hot(i,myvocabsiz) for i in mysent]\n",
        "print(encodsent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkFOnNPHgGTX",
        "outputId": "f11a2fe6-a020-4c8d-9efc-e54366e9a7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[22, 1, 7], [22, 29, 29, 3], [22, 29, 14, 27], [15, 4, 19], [15, 8, 13, 17], [15, 7, 21, 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding document to max length 5\n"
      ],
      "metadata": {
        "id": "CD4IZQCIiDVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lenght = 5\n",
        "padmyencodsent ="
      ],
      "metadata": {
        "id": "5WI5_lRmiYuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenght = 5\n",
        "padmysent = pad_sequences(encodsent, maxlen=lenght,padding='pre')\n",
        "print(padmysent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttPL-Yi4im9y",
        "outputId": "8ade123c-66a7-459a-d554-c48c096ad4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0 22  1  7]\n",
            " [ 0 22 29 29  3]\n",
            " [ 0 22 29 14 27]\n",
            " [ 0  0 15  4 19]\n",
            " [ 0 15  8 13 17]\n",
            " [ 0 15  7 21 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dPD2zO5AdF3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mymodel = Sequential()\n",
        "mymodel.add(Embedding(myvocabsiz, 8, input_length=lenght))\n",
        "mymodel.add(Flatten())\n",
        "mymodel.add(Dense(1, activation = 'sigmoid'))\n",
        "\n"
      ],
      "metadata": {
        "id": "1Szl5YBekQoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0GGeOsHl1nzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel.fit(padmysent,mysentlabels, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlOcb9bN2CKP",
        "outputId": "096be516-ec32-4101-ae71-546d8de182e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.7089 - accuracy: 0.3333\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7060 - accuracy: 0.3333\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7032 - accuracy: 0.3333\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7003 - accuracy: 0.3333\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6919 - accuracy: 0.6667\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6891 - accuracy: 0.6667\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6863 - accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.8333\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6808 - accuracy: 0.8333\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6780 - accuracy: 0.8333\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6753 - accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6725 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6698 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6670 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6643 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6615 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6588 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6560 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6533 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6505 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6450 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6422 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6394 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6366 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6338 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6310 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6282 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdaf9355550>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the Prediction part"
      ],
      "metadata": {
        "id": "lWPwPFeU2V4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topredict =['how tall are you', 'i am short']"
      ],
      "metadata": {
        "id": "QPhRQLhS2hF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 30\n",
        "encoded= [one_hot(d, vocab_size) for d in topredict]\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8Qtj7Lr2y-6",
        "outputId": "c1e5625e-58ea-4404-fc37-751ecfd59c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[22, 29, 1, 7], [15, 4, 25]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 5\n",
        "mypaded = pad_sequences(encoded, maxlen= max_length, padding='pre')\n",
        "print(mypaded)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KPs54mG3Tn-",
        "outputId": "48c787c9-bc6a-4ffa-9430-02c05640bf3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 22 29  1  7]\n",
            " [ 0  0 15  4 25]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = mymodel.predict(mypaded )"
      ],
      "metadata": {
        "id": "B9N4M_jo4BJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SFh2O0y4dyD",
        "outputId": "7ad5df4a-6fa5-405e-8543-625a2e73ddbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5466823 ]\n",
            " [0.48987478]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d8HgnFNn1rKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topredict =['i am short', 'how tall are you', 'what is your name', 'how are you']\n"
      ],
      "metadata": {
        "id": "fEDLI9EO1wEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 30\n",
        "encoded= [one_hot(d, vocab_size) for d in topredict]\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ed4270-132e-4fc1-b3df-407782b32053",
        "id": "UoIBRUrs10bR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15, 4, 25], [22, 29, 1, 7], [28, 29, 14, 20], [22, 1, 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 5\n",
        "mypaded = pad_sequences(encoded, maxlen= max_length, padding='pre')\n",
        "print(mypaded)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4e4746-b162-467d-b326-1d78fdc30425",
        "id": "uD3k2g4z149U"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0 15  4 25]\n",
            " [ 0 22 29  1  7]\n",
            " [ 0 28 29 14 20]\n",
            " [ 0  0 22  1  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = mymodel.predict(mypaded )"
      ],
      "metadata": {
        "id": "V-NfWGHt18pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "hQgXIiYF1-_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.around(ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2doM2oQ4QKP",
        "outputId": "c8c4f6e5-b193-4875-ad8c-ca43a0ff3c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    }
  ]
}